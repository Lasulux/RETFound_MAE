{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import tfimm\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " vit_large_patch16_224 (ViT)  (None, 1024)             303301632 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " head (Dense)                (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 303,826,945\n",
      "Trainable params: 525,313\n",
      "Non-trainable params: 303,301,632\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the base model\n",
    "model_name = \"vit_large_patch16_224\"\n",
    "base_model = tfimm.create_model(\n",
    "    model_name,\n",
    "    nb_classes=0  # this removes the final layer\n",
    ")\n",
    "\n",
    "# Load base_model weights (by_name=True because nb_classes=0 removes a layer)\n",
    "model_path = \"RETFound_CFP_weights.h5\" # get from RETFound github\n",
    "\n",
    "base_model.load_weights(model_path, by_name=True, skip_mismatch=False)\n",
    "base_model.trainable = False\n",
    "# base_model.summary()\n",
    "\n",
    "# Input layer\n",
    "input_shape = (224, 224, 3)\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# ViT layer\n",
    "x = base_model(inputs)\n",
    "\n",
    "# Add layers to match the original architecture leading up to the 'head' layer\n",
    "# x = tf.keras.layers.LayerNormalization()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "prediction = tf.keras.layers.Dense(1, activation='relu',name='head')(x)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=prediction)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_image_from_each_directory(root_dir):\n",
    "    image_paths = []\n",
    "\n",
    "    for class_dir in os.listdir(root_dir):\n",
    "        full_class_dir = os.path.join(root_dir, class_dir)\n",
    "        if os.path.isdir(full_class_dir):\n",
    "            first_image = sorted(os.listdir(full_class_dir))[0]\n",
    "            image_path = os.path.join(full_class_dir, first_image)\n",
    "            image_paths.append(image_path)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    left_half = tf.image.crop_to_bounding_box(image, offset_height=0, offset_width=0, target_height=512, target_width=512)\n",
    "    image = tf.image.resize(left_half, [224, 224])  # Resize to a fixed size, e.g., 224x224\n",
    "    image = image / 255.0  # Normalize to [0,1] range\n",
    "    return image\n",
    "\n",
    "def create_dataset(image_paths):\n",
    "    image_paths = tf.convert_to_tensor(image_paths)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    dataset = dataset.map(lambda path: load_and_preprocess_image(path))\n",
    "    return dataset\n",
    "\n",
    "# Define the root directory of your dataset\n",
    "root_dir = \"./data/OIMHS dataset/Images\"\n",
    "\n",
    "# Get the first image from each directory\n",
    "image_paths = get_first_image_from_each_directory(root_dir)\n",
    "\n",
    "# Create the dataset\n",
    "image_dataset = create_dataset(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/OIMHS dataset/Demographics of the participants.xlsx')\n",
    "df[\"Age(years)\"]\n",
    "labels = df[\"Age(years)\"]\n",
    "labels_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "full_dataset = tf.data.Dataset.zip((image_dataset,labels_dataset))\n",
    "# full_dataset = full_dataset.map(lambda x,y: {\"image\":x,\"label\":y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset= full_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=\n",
      "array([[[[0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         ...,\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079]],\n",
      "\n",
      "        [[0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         ...,\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079]],\n",
      "\n",
      "        [[0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         ...,\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.13945661, 0.13945661, 0.13945661],\n",
      "         [0.15400271, 0.15400271, 0.15400271],\n",
      "         [0.1735503 , 0.1735503 , 0.1735503 ],\n",
      "         ...,\n",
      "         [0.14651932, 0.14651932, 0.14651932],\n",
      "         [0.17506976, 0.17506976, 0.17506976],\n",
      "         [0.20666245, 0.20666245, 0.20666245]],\n",
      "\n",
      "        [[0.20678216, 0.20678216, 0.20678216],\n",
      "         [0.14531764, 0.14531764, 0.14531764],\n",
      "         [0.17641127, 0.17641127, 0.17641127],\n",
      "         ...,\n",
      "         [0.14901912, 0.14901912, 0.14901912],\n",
      "         [0.16078432, 0.16078432, 0.16078432],\n",
      "         [0.24816182, 0.24816182, 0.24816182]],\n",
      "\n",
      "        [[0.11492527, 0.11492527, 0.11492527],\n",
      "         [0.1386545 , 0.1386545 , 0.1386545 ],\n",
      "         [0.2524607 , 0.2524607 , 0.2524607 ],\n",
      "         ...,\n",
      "         [0.14055508, 0.14055508, 0.14055508],\n",
      "         [0.15206204, 0.15206204, 0.15206204],\n",
      "         [0.21342395, 0.21342395, 0.21342395]]]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([58], dtype=int64)>)\n"
     ]
    }
   ],
   "source": [
    "for data in full_dataset.take(1):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = full_dataset.take(int(0.8 * len(full_dataset)))  # Take 80% of the data for training\n",
    "validation_dataset = full_dataset.skip(int(0.8 * len(full_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " vit_large_patch16_224 (ViT)  (None, 1024)             303301632 \n",
      "                                                                 \n",
      " head (Dense)                (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 303,302,657\n",
      "Trainable params: 1,025\n",
      "Non-trainable params: 303,301,632\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the base model\n",
    "model_name = \"vit_large_patch16_224\"\n",
    "base_model = tfimm.create_model(\n",
    "    model_name,\n",
    "    nb_classes=0  # this removes the final layer\n",
    ")\n",
    "\n",
    "# Load base_model weights (by_name=True because nb_classes=0 removes a layer)\n",
    "model_path = \"RETFound_oct_weights.h5\"\n",
    "\n",
    "base_model.load_weights(model_path, by_name=True, skip_mismatch=False)\n",
    "base_model.trainable = False\n",
    "# base_model.summary()\n",
    "\n",
    "# Input layer\n",
    "input_shape = (224, 224, 3)\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# ViT layer\n",
    "x = base_model(inputs)\n",
    "\n",
    "# Add layers to match the original architecture leading up to the 'head' layer\n",
    "# x = tf.keras.layers.LayerNormalization()(x)\n",
    "# x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "prediction = tf.keras.layers.Dense(1, activation='relu',name='head')(x)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=prediction)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"mlp\" (type MLP).\n\nfailed to allocate memory [Op:AddV2]\n\nCall arguments received:\n  • x=tf.Tensor(shape=(1, 197, 1024), dtype=float32)\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create the base model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvit_large_patch16_224\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mtfimm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnb_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# this removes the final layer\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load base_model weights (by_name=True because nb_classes=0 removes a layer)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETFound_oct_weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kakas\\anaconda3\\envs\\retfound_mae\\lib\\site-packages\\tfimm\\models\\factory.py:108\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(model_name, pretrained, model_path, in_channels, nb_classes, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Otherwise, we build a new model and transfer the weights to it. This is because\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# some parameter changes (in_channels and nb_classes) require changing the shape of\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# some weights or dropping of others. And there might be non-trivial interactions\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# between various parameters, e.g., global_pool can be None only if nb_classes is 0.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(cfg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m--> 108\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdummy_inputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call model to build layers\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Now we need to transfer weights from loaded_model to model\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loaded_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kakas\\anaconda3\\envs\\retfound_mae\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\kakas\\anaconda3\\envs\\retfound_mae\\lib\\site-packages\\tfimm\\architectures\\vit.py:468\u001b[0m, in \u001b[0;36mViT.call\u001b[1;34m(self, x, training, return_features)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    467\u001b[0m     features \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 468\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_features:\n\u001b[0;32m    470\u001b[0m         x, features \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[1;32mc:\\Users\\kakas\\anaconda3\\envs\\retfound_mae\\lib\\site-packages\\tfimm\\architectures\\vit.py:447\u001b[0m, in \u001b[0;36mViT.forward_features\u001b[1;34m(self, x, training, return_features)\u001b[0m\n\u001b[0;32m    444\u001b[0m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[1;32m--> 447\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_features:\n\u001b[0;32m    449\u001b[0m         x, block_features \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[1;32mc:\\Users\\kakas\\anaconda3\\envs\\retfound_mae\\lib\\site-packages\\tfimm\\architectures\\vit.py:232\u001b[0m, in \u001b[0;36mViTBlock.call\u001b[1;34m(self, x, training, return_features)\u001b[0m\n\u001b[0;32m    230\u001b[0m shortcut \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    231\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m--> 232\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m    234\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m shortcut\n",
      "File \u001b[1;32mc:\\Users\\kakas\\anaconda3\\envs\\retfound_mae\\lib\\site-packages\\tfimm\\layers\\transformers.py:212\u001b[0m, in \u001b[0;36mMLP.call\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m    210\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[0;32m    211\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop1(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m--> 212\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop2(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"mlp\" (type MLP).\n\nfailed to allocate memory [Op:AddV2]\n\nCall arguments received:\n  • x=tf.Tensor(shape=(1, 197, 1024), dtype=float32)\n  • training=False"
     ]
    }
   ],
   "source": [
    "# Create the base model\n",
    "model_name = \"vit_large_patch16_224\"\n",
    "base_model = tfimm.create_model(\n",
    "    model_name,\n",
    "    nb_classes=0  # this removes the final layer\n",
    ")\n",
    "\n",
    "# Load base_model weights (by_name=True because nb_classes=0 removes a layer)\n",
    "model_path = \"RETFound_oct_weights.h5\"\n",
    "\n",
    "base_model.load_weights(model_path, by_name=True, skip_mismatch=False)\n",
    "base_model.trainable = True\n",
    "base_model.summary()\n",
    "\n",
    "# Input layer\n",
    "input_shape = (224, 224, 3)\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "\n",
    "\n",
    "# ViT layer\n",
    "x = base_model(inputs)\n",
    "\n",
    "# Add layers to match the original architecture leading up to the 'head' layer\n",
    "# x = tf.keras.layers.LayerNormalization()(x)\n",
    "# x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "prediction = tf.keras.layers.Dense(1, activation='relu',name='head')(x)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# launch from console with command: tensorboard --logdir=./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 54s 415ms/step - loss: 37.2498 - mean_absolute_error: 37.2498 - val_loss: 15.3315 - val_mean_absolute_error: 15.3315\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 38s 380ms/step - loss: 7.9966 - mean_absolute_error: 7.9966 - val_loss: 8.5096 - val_mean_absolute_error: 8.5096\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 38s 375ms/step - loss: 7.4488 - mean_absolute_error: 7.4488 - val_loss: 8.9324 - val_mean_absolute_error: 8.9324\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 7.2446 - mean_absolute_error: 7.2446 - val_loss: 8.5424 - val_mean_absolute_error: 8.5424\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 7.1487 - mean_absolute_error: 7.1487 - val_loss: 8.4421 - val_mean_absolute_error: 8.4421\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 7.1648 - mean_absolute_error: 7.1648 - val_loss: 8.3790 - val_mean_absolute_error: 8.3790\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 38s 384ms/step - loss: 7.2152 - mean_absolute_error: 7.2152 - val_loss: 8.3183 - val_mean_absolute_error: 8.3183\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 7.1983 - mean_absolute_error: 7.1983 - val_loss: 8.2716 - val_mean_absolute_error: 8.2716\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 7.0950 - mean_absolute_error: 7.0950 - val_loss: 8.3247 - val_mean_absolute_error: 8.3247\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 7.0022 - mean_absolute_error: 7.0022 - val_loss: 8.1485 - val_mean_absolute_error: 8.1485\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 38s 382ms/step - loss: 7.0284 - mean_absolute_error: 7.0284 - val_loss: 8.2075 - val_mean_absolute_error: 8.2075\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 37s 375ms/step - loss: 6.9673 - mean_absolute_error: 6.9673 - val_loss: 8.3774 - val_mean_absolute_error: 8.3774\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 6.9636 - mean_absolute_error: 6.9636 - val_loss: 8.3783 - val_mean_absolute_error: 8.3783\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 37s 375ms/step - loss: 6.9045 - mean_absolute_error: 6.9045 - val_loss: 8.3198 - val_mean_absolute_error: 8.3198\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 6.9469 - mean_absolute_error: 6.9469 - val_loss: 8.3953 - val_mean_absolute_error: 8.3953\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 39s 390ms/step - loss: 6.9851 - mean_absolute_error: 6.9851 - val_loss: 8.3929 - val_mean_absolute_error: 8.3929\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 6.8448 - mean_absolute_error: 6.8448 - val_loss: 8.1567 - val_mean_absolute_error: 8.1567\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 7.0070 - mean_absolute_error: 7.0070 - val_loss: 8.3915 - val_mean_absolute_error: 8.3915\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 38s 384ms/step - loss: 6.8386 - mean_absolute_error: 6.8386 - val_loss: 8.4153 - val_mean_absolute_error: 8.4153\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 6.9382 - mean_absolute_error: 6.9382 - val_loss: 8.2800 - val_mean_absolute_error: 8.2800\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 40s 398ms/step - loss: 6.9010 - mean_absolute_error: 6.9010 - val_loss: 8.0898 - val_mean_absolute_error: 8.0898\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 6.7689 - mean_absolute_error: 6.7689 - val_loss: 8.2585 - val_mean_absolute_error: 8.2585\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 7.0707 - mean_absolute_error: 7.0707 - val_loss: 8.1655 - val_mean_absolute_error: 8.1655\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 6.8735 - mean_absolute_error: 6.8735 - val_loss: 8.1547 - val_mean_absolute_error: 8.1547\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 6.7223 - mean_absolute_error: 6.7223 - val_loss: 8.0966 - val_mean_absolute_error: 8.0966\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 6.8574 - mean_absolute_error: 6.8574 - val_loss: 8.8071 - val_mean_absolute_error: 8.8071\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 6.9556 - mean_absolute_error: 6.9556 - val_loss: 8.4799 - val_mean_absolute_error: 8.4799\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 6.7738 - mean_absolute_error: 6.7738 - val_loss: 8.1618 - val_mean_absolute_error: 8.1618\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 36s 365ms/step - loss: 6.9070 - mean_absolute_error: 6.9070 - val_loss: 8.0338 - val_mean_absolute_error: 8.0338\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 6.9456 - mean_absolute_error: 6.9456 - val_loss: 8.0609 - val_mean_absolute_error: 8.0609\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 6.7120 - mean_absolute_error: 6.7120 - val_loss: 8.5597 - val_mean_absolute_error: 8.5597\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 7.0317 - mean_absolute_error: 7.0317 - val_loss: 8.1251 - val_mean_absolute_error: 8.1251\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 6.7722 - mean_absolute_error: 6.7722 - val_loss: 8.0846 - val_mean_absolute_error: 8.0846\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 6.7625 - mean_absolute_error: 6.7625 - val_loss: 8.0719 - val_mean_absolute_error: 8.0719\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 6.9827 - mean_absolute_error: 6.9827 - val_loss: 8.7318 - val_mean_absolute_error: 8.7318\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 38s 379ms/step - loss: 6.6964 - mean_absolute_error: 6.6964 - val_loss: 8.1202 - val_mean_absolute_error: 8.1202\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 38s 384ms/step - loss: 6.9511 - mean_absolute_error: 6.9511 - val_loss: 8.0672 - val_mean_absolute_error: 8.0672\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 36s 364ms/step - loss: 6.6422 - mean_absolute_error: 6.6422 - val_loss: 8.0765 - val_mean_absolute_error: 8.0765\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 36s 366ms/step - loss: 6.7345 - mean_absolute_error: 6.7345 - val_loss: 8.0793 - val_mean_absolute_error: 8.0793\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 36s 364ms/step - loss: 6.6349 - mean_absolute_error: 6.6349 - val_loss: 8.3887 - val_mean_absolute_error: 8.3887\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 36s 362ms/step - loss: 6.6744 - mean_absolute_error: 6.6744 - val_loss: 8.1680 - val_mean_absolute_error: 8.1680\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 36s 364ms/step - loss: 6.6994 - mean_absolute_error: 6.6994 - val_loss: 8.1848 - val_mean_absolute_error: 8.1848\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 6.6647 - mean_absolute_error: 6.6647 - val_loss: 8.4439 - val_mean_absolute_error: 8.4439\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 38s 387ms/step - loss: 6.5867 - mean_absolute_error: 6.5867 - val_loss: 8.1194 - val_mean_absolute_error: 8.1194\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 6.7670 - mean_absolute_error: 6.7670 - val_loss: 8.1626 - val_mean_absolute_error: 8.1626\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 6.7083 - mean_absolute_error: 6.7083 - val_loss: 8.1482 - val_mean_absolute_error: 8.1482\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 38s 380ms/step - loss: 6.7502 - mean_absolute_error: 6.7502 - val_loss: 8.3047 - val_mean_absolute_error: 8.3047\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 38s 382ms/step - loss: 6.5679 - mean_absolute_error: 6.5679 - val_loss: 8.5456 - val_mean_absolute_error: 8.5456\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 38s 379ms/step - loss: 6.6549 - mean_absolute_error: 6.6549 - val_loss: 8.3042 - val_mean_absolute_error: 8.3042\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 6.6298 - mean_absolute_error: 6.6298 - val_loss: 8.1145 - val_mean_absolute_error: 8.1145\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "epochs=50\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67.34243 ],\n",
       "       [69.85764 ],\n",
       "       [69.15124 ],\n",
       "       [68.004135],\n",
       "       [69.25767 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_dataset)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([74], shape=(1,), dtype=int64)\n",
      "tf.Tensor([59], shape=(1,), dtype=int64)\n",
      "tf.Tensor([51], shape=(1,), dtype=int64)\n",
      "tf.Tensor([51], shape=(1,), dtype=int64)\n",
      "tf.Tensor([78], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "for images, labels in test_dataset.take(6):\n",
    "    y_true.append(tf.cast(labels, tf.int32))\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.65756989])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[0].numpy() - predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumdiff=0\n",
    "for i in range(len(y_true)):\n",
    "    absdiff = np.abs(y_true[i].numpy() - predictions[i])\n",
    "    sumdiff+=absdiff\n",
    "mean_diff = sumdiff/(len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.28258362])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_diff\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retfound_mae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
