{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naturalist 3\n",
    "\n",
    "# Create the base model\n",
    "model_name = \"vit_large_patch16_224\"\n",
    "base_model = tfimm.create_model(\n",
    "    model_name,\n",
    "    nb_classes=0  # this removes the final layer\n",
    ")\n",
    "\n",
    "# Load base_model weights (by_name=True because nb_classes=0 removes a layer)\n",
    "model_path = \"RETFound_CFP_weights.h5\" # get from RETFound github\n",
    "\n",
    "base_model.load_weights(model_path, by_name=True, skip_mismatch=False)\n",
    "base_model.trainable = False\n",
    "# base_model.summary()\n",
    "\n",
    "# Input layer\n",
    "input_shape = (224, 224, 3)\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# ViT layer\n",
    "x = base_model(inputs)\n",
    "\n",
    "x = tf.keras.layers.Dense(2048)(x) \n",
    "x = tf.keras.layers.Dense(1024)(x)\n",
    "x = tf.keras.layers.Dense(1024)(x)\n",
    "\n",
    "prediction = tf.keras.layers.Dense(1, activation='relu',name='head')(x)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=prediction)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ala Pali\n",
    "\n",
    "# Create the base model\n",
    "model_name = \"vit_large_patch16_224\"\n",
    "base_model = tfimm.create_model(\n",
    "    model_name,\n",
    "    nb_classes=0  # this removes the final layer\n",
    ")\n",
    "\n",
    "# Load base_model weights (by_name=True because nb_classes=0 removes a layer)\n",
    "model_path = \"RETFound_CFP_weights.h5\" # get from RETFound github\n",
    "\n",
    "base_model.load_weights(model_path, by_name=True, skip_mismatch=False)\n",
    "base_model.trainable = False\n",
    "# base_model.summary()\n",
    "\n",
    "# Input layer\n",
    "input_shape = (224, 224, 3)\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# ViT layer\n",
    "x = base_model(inputs)\n",
    "\n",
    "# Add layers to match the original architecture leading up to the 'head' layer\n",
    "# x = tf.keras.layers.LayerNormalization()(x)\n",
    "# x = tf.keras.layers.Dense(2048, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(2048, use_bias=False)(x) \n",
    "x = tf.keras.layers.BatchNormalization()(x)  # Adding Batch Normalization\n",
    "x = tf.keras.layers.Activation('relu')(x) # non-linearity\n",
    "x = tf.keras.layers.Dropout(0.5)(x)  # Adding Dropout\n",
    "\n",
    "x = tf.keras.layers.Dense(1024, use_bias=False)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)  # Adding Batch Normalization\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)  # Adding Dropout\n",
    "\n",
    "x = tf.keras.layers.Dense(1024, use_bias=False)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)  # Adding Batch Normalization\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)  # Adding Dropout\n",
    "\n",
    "prediction = tf.keras.layers.Dense(1, activation='relu',name='head')(x)\n",
    "\n",
    "# early stopping, patience 50 kb - ez kevés, mert megáll 7-8 évnél\n",
    "# felezve negyedelve a neuronok számát, h megy? - rosszul megy\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=prediction)\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
